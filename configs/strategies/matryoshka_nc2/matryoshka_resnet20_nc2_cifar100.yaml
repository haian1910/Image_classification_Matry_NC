dataset: cifar100
data_root: ./data

model:
  name: matryoshka_resnet20
  pretrained: False
  num_classes: 100
  # Matryoshka specific parameters
  feature_dims: [128, 256, 384, 512]
  adaptive: True

# Training parameters
epochs: 200
batch_size: 128
optimizer:
  name: SGD
  lr: 0.1
  momentum: 0.9
  weight_decay: 5e-4

scheduler:
  name: MultiStepLR
  milestones: [60, 120, 160]
  gamma: 0.2

# Data augmentation
mixup_alpha: 0.0  # Disable mixup for distillation
cutmix_alpha: 0.0

# Knowledge Distillation settings - NC2
distill:
  enable: true
  teacher_model: cifar_resnet110
  teacher_pretrained: true
  kd_method: nc2
  ori_loss_weight: 0.5
  kd_loss_weight: 3.0
  kd_loss_kwargs:
    num_classes: 100
    nc2_lambda: 1.0       # Weight for NC2 Gram matrix loss
    ortho_lambda: 0.1     # Weight for orthogonality regularization
    ema_momentum: 0.95    # EMA momentum for class means
    nc2_alpha: 0.5        # Interpolation between batch and EMA losses

# Matryoshka specific training
matryoshka:
  progressive_training: true
  warmup_epochs: 10
  final_epochs: 20
  dimension_weights: [0.5, 0.7, 0.9, 1.0]  # Progressive importance

# Logging and checkpointing
log_interval: 50
save_freq: 50
eval_freq: 10

# Paths
exp_dir: ./experiments/matryoshka_nc2_test
